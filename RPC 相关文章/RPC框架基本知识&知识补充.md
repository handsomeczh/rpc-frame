# RPC框架基础知识

​	RPC 的主要功能目标是让构建分布式计算（应用）更容易，在提供强大的远程调用能力时不损失本地调用的语义简洁性。为实现该目标，RPC 框架需提供一种透明调用机制，让使用者不必显式的区分本地调用和远程调用。

![image-20240326161307144](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240326161307144.png)

### 优点：

- 分布式设计
- 部署灵活
- 结构服务
- 扩展性强

### 特性：

- RPC框架一般使用[长连接]()，不必每次通信都要3次握手，减少网络开销
- RPC框架一般都有注册中心，有丰富的监控管理。发布、下线接口、动态扩展等，对调用方来说时无感知、统一化的操作协议私密，安全性较高
- RPC协议更简单内容更小，效率更高，服务化架构、服务化治理，RPC框架是一个强力的支撑

### 基本架构：

![image-20240326162621405](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240326162621405.png)

### 调用流程：

![image-20240326163656957](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240326163656957.png)

### 涉及到的技术：

1. 动态代理

   生成Client Stub（客户端存根）和Server Stub（服务端存根）的时候需要用到Java动态代理技术

2. 序列化

   在网络中，所有数据都将会被转化为字节进行传送，需要对这些参数进行序列化和反序列化操作。

3. NIO通信

   Java提供了NIO的解决方案，java7也提供了优秀的NIO.2支持。可以采用Netty或者mina框架来解决NIO数据传输的问题。开源的RPC框架Dubbo就是采用NIO通信，集成支持netty、mina、grizzly。

4. 服务注册中心

   通过注册中心，让客户端连接调用服务端所发布的服务。主流的注册中心组件：Redis、Zookeeper、Consul、Etcd。Dubbo采用的是ZooKeeper提供服务注册与发现功能。

5. 负载均衡

   在高并发的场景下，需要多个节点或者集群来提升整体吞吐能力

6. 健康检查

   包括客户端心跳和服务端主动探测两种方式

#### RPC深入解析

##### 序列化技术

**作用**

在网络传输中，数据必须采用二进制形式， 所以在RPC调用过程中， 需要采用序列化技术，对入参对象和返回值对象进行序列化与反序列化。

**如何序列化**

自定义二进制协议来是实现序列化

![img](https://pic2.zhimg.com/80/v2-649da26d6c60095cd104516e99d78a91_1440w.webp)**序列化的处理要素**

1. 解析效率：序列化协议应该首要考虑的因素，像xml/json解析起来比较耗时，需要解析doom树，二进制自定义协议解析起来效率要快很多。
2. 压缩率：同样一个对象，xml/json传输起来有大量的标签冗余信息，信息有效性低，二进制自定义协议占用的空间相对来说会小很多。
3. 扩展性与兼容性：是否能够利于信息的扩展，并且增加字段后旧版客户端是否需要强制升级，这都是需要考虑的问题，在自定义二进制协议时候，要做好充分考虑设计。
4. 可读性与可调试性：xml/json的可读性会比二进制协议好很多，并且通过网络抓包是可以直接读取，二进制则需要反序列化才能查看其内容。
5. 跨语言：有些序列化协议是与开发语言紧密相关的，例如dubbo的Hessian序列化协议就只能支持Java的RPC调用。
6. 通用性：xml/json非常通用，都有很好的第三方解析库，各个语言解析起来都十分方便，二进制数据的处理方面也有Protobuf和Hessian等插件，在做设计的时候尽量做到较好的通用性。

**常用的序列化技术**

1. JDK原生序列化，通过实现Serializable接口。通过ObjectOutPutSream和ObjectInputStream对象进行序列化及反序列化.
2. JSON序列化。一般在HTTP协议的RPC框架通信中，会选择JSON方式。JSON具有较好的扩展性、可读性和通用性。但JSON序列化占用空间开销较大,没有JAVA的强类型区分，需要通过反射解决，解析效率和压缩率都较差。如果对并发和性能要求较高，或者是传输数据量较大的场景，不建议采用JSON序列化方式。
3. Hessian2序列化。Hessian 是一个动态类型，二进制序列化，并且支持跨语言特性的序列化框架。Hessian 性能上要比 JDK、JSON 序列化高效很多，并且生成的字节数也更小。有非常好的兼容性和稳定性，所以 Hessian 更加适合作为 RPC 框架远程通信的序列化协议。

Hessian2序列化

```java
...
User user = new User();
user.setName("laowang");

//user对象序列化处理
ByteArrayOutputStream bos = new ByteArrayOutputStream();
Hessian2Output output = new Hessian2Output(bos);
output.writeObject(user);
output.flushBuffer();
byte[] data = bos.toByteArray();
bos.close();

//user对象反序列化处理
ByteArrayInputStream bis = new ByteArrayInputStream(data);
Hessian2Input input = new Hessian2Input(bis);
User user = (User) input.readObject();
input.close();

System.out.println(user);
...
```

**Hessian自身也存在一些缺陷，大家在使用过程中要注意：**

1. 对Linked系列对象不支持，比如LinkedHashMap、LinkedHashSet 等，但可以通过CollectionSerializer类修复。

2. Locale 类不支持，可以通过扩展 ContextSerializerFactory 类修复。

3. Byte/Short 在反序列化的时候会转成 Integer。

##### 动态处理

RPC的调用内部核心技术采用的就是动态代理

**JDK如何实现动态代理**

```java
public class JdkProxyTest {

    /**
     * 定义用户的接口
     */
    public interface User {
        String job();
    }

    /**
     * 实际的调用对象
     */
    public static class Teacher {

        public String invoke(){
            return "i'm Teacher";
        }
    }

    /**
     * 创建JDK动态代理类
     */
    public static class JDKProxy implements InvocationHandler {
        private Object target;

        JDKProxy(Object target) {
            this.target = target;
        }

        @Override
        public Object invoke(Object proxy, Method method, Object[] paramValues) {
            return ((Teacher)target).invoke();
        }
    }

        public static void main(String[] args){
            // 构建代理器
            JDKProxy proxy = new JDKProxy(new Teacher());
            ClassLoader classLoader = ClassLoaderUtils.getClassLoader();

            // 生成代理类
            User user = (User) Proxy.newProxyInstance(classLoader, new Class[]{User.class}, 
proxy);

            // 接口调用
            System.out.println(user.job());
        }
}
```

**JDK动态代理实现原理**

代理类 $Proxy里面会定义相同签名的接口，然后内部会定义一个变量绑定JDKProxy代理对象，当调用User.job接口方法，实质上调用的是JDKProxy.invoke()方法。![img](https://pic1.zhimg.com/80/v2-503c48c07866e38018362315d8f74808_1440w.webp)

##### 服务注册发现

**注册与发现流程**

服务注册：服务提供方将对外暴露的接口发布到注册中心内，注册中心为了检测服务的有效状态，一般会建立双向心跳机制。
服务订阅：服务调用方去注册中心查找并订阅服务提供方的 IP，并缓存到本地用于后续调用

**基于zookeeper实现**

1. 在 ZooKeeper 中创建一个服务根路径，可以根据接口名命名（例
   如：/micro/service/com.laowang.orderService），在这个路径再创建服务提供方与调用方目录（server、
   client），分别用来存储服务提供方和调用方的节点信息。
2. 服务端发起注册时，会在服务提供方目录中创建一个临时节点，节点中存储注册信息。
3. 客户端发起订阅时，会在服务调用方目录中创建一个临时节点，节点中存储调用方的信息，同时watch 服务提供方的目录（/micro/service/com.laowang.orderService/server）中所有的服务节点数据。当服务端产生变化时ZK就会通知给订阅的客户端。

**ZooKeeper方案的特点：**
强一致性，ZooKeeper 集群的每个节点的数据每次发生更新操作，都会通知其它 ZooKeeper 节点同时执行更新。

##### 健康检测

**为什么需要做健康检测**

比如网络中的波动，硬件设施的老化等等。可能造成集群当中的某个节点存在问题，无法正常调用。

**健康检测实现分析**

心跳检测的过程总共包含以下状态:健康状态、波动状态、失败状态。

**完善的解决方案**

1. 阈值： 健康监测增加失败阈值记录。
2. 成功率： 可以再追加调用成功率的记录（成功次数/总次数）。
3. 探针： 对服务节点有一个主动的存活检测机制。

##### 网络IO模型

##### 零拷贝

系统内核处理 IO 操作分为两个阶段：等待数据和拷贝数据。

等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中。

拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中

所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，都可以通过一种方式，让应用进程向用户空间写入或者读取数据，就如同直接向内核空间写入或者读取数据一样，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。

**PRC框架的零拷贝应用**

Netty 的零拷贝则有些不一样，他完全站在了用户空间上，也就是基于 JVM 之上。

RPC 并不会把请求参数作为一个整体数据包发送到对端机器上，中间可能会拆分，也可能会合并其他请求，所以消息都需要有边界。接收到消息之后，需要对数据包进行处理，根据边界对数据包进行分割和合并，最终获得完整的消息。

**Netty零拷贝主要体现在三个方面：**

1、Netty的接收和发送ByteBuffer是采用DIRECT BUFFERS，使用堆外的直接内存（内存对象分配在JVM中堆以外的内存）进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果采用传统堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后写入Socket中。
2、Netty提供了组合Buffer对象，也就是CompositeByteBuf 类，可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。

3、Netty的文件传输采用了FileRegion 中包装 NIO 的 FileChannel.transferT o() 方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。

零拷贝带来的作用就是避免没必要的 CPU 拷贝，减少了 CPU 在用户空间与内核空间之间的上下文切换，从而提升了网络通信效率与应用程序的整体性能。

##### 时间轮

**为什么需要时间轮**

在Dubbo中，为增强系统的容错能力，会有相应的监听判断处理机制。比如RPC调用的超时机制的实现，消费者判断RPC调用是否超时，如果超时会将超时结果返回给应用层。在Dubbo最开始的实现中，是将所有的返回结果（DefaultFuture）都放入一个集合中，并且通过一个定时任务，每隔一定时间间隔就扫描所有的future，逐个判断是否超时。

这样的实现方式虽然比较简单，但是存在一个问题就是会有很多无意义的遍历操作开销。比如一个RPC调用的超时时间是10秒，而设置的超时判定的定时任务是2秒执行一次，那么可能会有4次左右无意义的循环检测判断操作。

为了解决上述场景中的类似问题，Dubbo借鉴Netty，引入了时间轮算法，减少无意义的轮询判断操作。

**时间轮原理**

对于以上问题， 目的是要减少额外的扫描操作就可以了。比如说一个定时任务是在5 秒之后执行，那么在 4.9秒之后才扫描这个定时任务，这样就可以极大减少 CPU开销。这时我们就可以利用时钟轮的机制了。

时钟轮的实质上是参考了生活中的时钟跳动的原理，那么具体是如何实现呢？
在时钟轮机制中，有时间槽和时钟轮的概念，时间槽就相当于时钟的刻度；而时钟轮就相当于指针跳动的一个周期，我们可以将每个任务放到对应的时间槽位上。

如果时钟轮有 10 个槽位，而时钟轮一轮的周期是 10 秒，那么我们每个槽位的单位时间就是 1 秒，而下一层时间轮的周期就是 100 秒，每个槽位的单位时间也就是 10 秒，这就好比秒针与分针， 在秒针周期下， 刻度单位为
秒， 在分针周期下， 刻度为分。

假设现在我们有 3 个任务，分别是任务 A（0.9秒之后执行）、任务 B（2.1秒后执行）与任务 C（12.1秒之后执
行），我们将这 3 个任务添加到时钟轮中，任务 A 被放到第 0 槽位，任务 B 被放到第 2槽位，任务 C 被放到下一
层时间轮的第2个槽位。

通过这个场景我们可以了解到，时钟轮的扫描周期仍是最小单位1秒，但是放置其中的任务并没有反复扫描，每个
任务会按要求只扫描执行一次， 这样就能够很好的解决CPU 浪费的问题。

**DUBBO中的时间轮原理实现**

主要是通过Timer，Timeout，TimerT ask几个接口定义了一个定时器的模型，再通过HashedWheelTimer这个类实现了一个时间轮定时器（默认的时间槽的数量是512，可以自定义这个值）。它对外提供了简单易用的接口，只需要调用newTimeout接口，就可以实现对只需执行一次任务的调度。通过该定时器，Dubbo在响应的场景中实现了高效的任务调度。

**时间轮在RPC的应用**

调用超时： 上面所讲的客户端调用超时的处理，就可以应用到时钟轮，我们每发一次请求，都创建一个处理请求超时的定时任务放到时钟轮里，在高并发、高访问量的情况下，时钟轮每次只轮询一个时间槽位中的任务，这样会节省大量的 CPU。

启动加载： 调用端与服务端启动也可以应用到时钟轮，比如说在服务启动完成之后要去加载缓存，执行定时任务等， 都可以放在时钟轮里

定时心跳检测： RPC 框架调用端定时向服务端发送的心跳检测，来维护连接状态，我们可以将心跳的逻辑封装为一个心跳任务，放到时钟轮里。心跳是要定时重复执行的，而时钟轮中的任务执行一遍就被移除了，对于这种需要重复执行的定时任务我们该如何处理呢？我们在定时任务逻辑结束的最后，再加上一段逻辑， 重设这个任务的执行时间，把它重新丢回到时钟轮里。这样就可以实现循环执行

#### PRC高级应用

##### 异步处理机制

**为什么采用异步**

如果采用同步调用， CPU 大部分的时间都在等待而没有去计算，从而导致 CPU 的利用率不够。RPC 请求比较耗时的原因主要是在哪里？在大多数情况下，RPC 本身处理请求的效率是在毫秒级的。RPC 请求的耗时大部分都是业务耗时。

**调用端实现异步**

常用的方式就是Future 方式，它是返回 Future 对象，通过GET方式获取结果；或者采用入参为 Callback 对象的回调方式，处理结果。

基于RPC的DUBBO框架是如何实现异步调用呢？

![img](https://pic4.zhimg.com/80/v2-17bd6a3b10e445fd932be2973fe73173_1440w.webp)

**服务端实现异步**

为了提升性能，连接请求与业务处理不会放在一个线程处理， 这个就是服务端的异步化。服务端业务处理逻辑加入异步处理机制。在RPC 框架提供一种回调方式，让业务逻辑可以异步处理，处理完之后调用 RPC 框架的回调接口

RPC 框架的异步策略主要是调用端异步与服务端异步。调用端的异步就是通过 Future 方式。
服务端异步则需要一种回调方式，让业务逻辑可以异步处理。这样就实现了RPC调用的全异步化

##### 路由和负载均衡

**为什么要用路由**

真实的环境中一般是以集群的方式提供服务，对于服务调用方来说，一个接口会有多个服务提供方同时提供服务，所以 RPC 在每次发起请求的时候，都需要从多个服务节点里面选取一个用于处理请求的服务节点。这就需要在RPC应用中增加路由功能。

**如何实现路由**

1. 服务注册发现方式：

   通过服务发现的方式从逻辑上看是可行，但注册中心是用来保证数据的一致性。通过服务发现方式来实现请求隔离并不理想。

2. RPC路由策略：

   从服务提供方节点集合里面选择一个合适的节点（负载均衡），把符合我们要求的节点筛选出来。这个就是路由策略：接收请求-->请求校验-->路由策略-->负载均衡-->

   有些场景下，可能还需要更细粒度的路由方式，比如说根据SESSIONID要落到相同的服务节点上以保持会话的有效性;

3. RPC框架中的负载均衡：

   RPC 的负载均衡是由 RPC 框架自身提供实现，自主选择一个最佳的服务节点，发起 RPC 调用请求。

   RPC 负载均衡策略一般包括轮询、随机、权重、最少连接等。Dubbo默认就是使用随机负载均衡策略。

   自适应的负载均衡策略
   RPC 的负载均衡完全由 RPC 框架自身实现，通过所配置的负载均衡组件，自主选择合适服务节点。这个就是自适应的负载均衡策略。
   具体如何实现？
   这就需要判定服务节点的处理能力。

   主要步骤：
   （1）添加计分器和指标采集器。
   （2）指标采集器收集服务节点 CPU 核数、CPU 负载以及内存占用率等指标。
   （3）可以配置开启哪些指标采集器，并设置这些参考指标的具体权重。
   （4）通过对服务节点的综合打分，最终计算出服务节点的实际权重，选择合适的服务节点。

##### 熔断限流

在实际生产环境中，每个服务节点都可能由于访问量过大而引起一系列问题，就需要业务提供方能够进行自我保护，从而保证在高访问量、高并发的场景下，系统依然能够稳定，高效运行。

在Dubbo框架中， 可以通过Sentinel来实现更为完善的熔断限流功能，服务端是具体如何实现限流逻辑的？

方法有很多种， 最简单的是计数器，还有平滑限流的滑动窗口、漏斗算法以及令牌桶算法等等。Sentinel采用是滑动窗口来实现的限流。

调用方的自我保护

一个服务 A 调用服务 B 时，服务 B 的业务逻辑又调用了服务 C，这时服务 C 响应超时，服务 B 就可能会因为堆积大量请求而导致服务宕机，由此产生服务雪崩的问题。

熔断机制：
熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换。
Sentinel 熔断降级组件它可以支持以下降级策略：

平均响应时间 ( DEGRADE_GRADE_RT )：当 1s 内持续进入 N 个请求，对应时刻的平均响应时间（秒级）均超过阈值（ count ，以 ms 为单位），那么在接下的时间窗口（ DegradeRule 中的 timeWindow ，以 s为单位）之内，对这个方法的调用都会自动地熔断（抛出 DegradeException ）。注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项Dcsp.sentinel.statistic.max.rt=xxx 来配置。

异常比例 ( DEGRADE_GRADE_EXCEPTION_RATIO )：当资源的每秒请求量 >= N（可配置），并且每秒异常总数占通过量的比值超过阈值（ DegradeRule 中的 count ）之后，资源进入降级状态，即在接下的时间窗口（ DegradeRule 中的 timeWindow ，以 s 为单位）之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 [0.0, 1.0] ，代表 0% - 100%。

异常数 ( DEGRADE_GRADE_EXCEPTION_COUNT )：当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60s，则结束熔断状态后仍可能再进入熔断状态。

##### 优雅启动

**启动预热**

启动预热就是让刚启动的服务，不直接承担全部的流量，而是让它随着时间的移动慢慢增加调用次数，最终让流量缓和运行一段时间后达到正常水平。

**实现**

首先要知道服务提供方的启动时间，有两种获取方法：
一种是服务提供方在启动的时候，主动将启动的时间发送给注册中心；
另一种就是注册中心来检测， 将服务提供方的请求注册时间作为启动时间。

调用方通过服务发现获取服务提供方的启动时间， 然后进行降权，减少被负载均衡选择的概率，从而实现预热过程。

在Dubbo框架中也引入了"warmup"特性，核心源码是
在" com.alibaba.dubbo.rpc.cluster.loadbalance.AbstractLoadBalance.java"中：

```java
protected int getWeight(Invoker<?> invoker, Invocation invocation) {
      // 先得到Provider的权重
      int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), 
Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT);
      if (weight > 0) {
          // 得到provider的启动时间戳
          long timestamp = invoker.getUrl().getParameter(Constants.REMOTE_TIMESTAMP_KEY, 0L);
          if (timestamp > 0L) {
              // provider已经运行时间
              int uptime = (int) (System.currentTimeMillis() ‐ timestamp);
              // 得到warmup的值，默认为10分钟
              int warmup = invoker.getUrl().getParameter(Constants.WARMUP_KEY, 
Constants.DEFAULT_WARMUP);
              // provider运行时间少于预热时间，那么需要重新计算权重weight（即需要降权）
              if (uptime > 0 && uptime < warmup) {
                  weight = calculateWarmupWeight(uptime, warmup, weight);
              }
          }
      }
      return weight;
  }

  static int calculateWarmupWeight(int uptime, int warmup, int weight) {
      // 随着provider的启动时间越来越长，慢慢提升权重weight
      int ww = (int) ( (float) uptime / ( (float) warmup / (float) weight ) );
      return ww < 1 ? 1 : (ww > weight ? weight : ww);
  }
```



##### 优雅关闭

**为什么需要优雅关闭？**

调用方会存在以下情况：目标服务已经下线;目标服务正在关闭中。

**如何实现优雅关闭？**

当服务提供方正在关闭，可以直接返回一个特定的异常给调用方。然后调用方把这个节点从健康列表挪出，并把其
他请求自动重试到其他节点。如需更为完善， 可以再加上主动通知机制。

在Dubbo框架中， 在以下场景中会触发优雅关闭：
JVM主动关闭( System.exit(int) ； JVM由于资源问题退出( OOM )； 应用程序接受到进程正常结束信号：SIGTERM 或 SIGINT 信号。
优雅停机是默认开启的，停机等待时间为10秒。可以通过配置 dubbo.service.shutdown.wait 来修改等待时间。Dubbo 推出了多段关闭的方式来保证服务完全无损。

## 知识补充

#### 本地调用

通常，在我们的代码中调用一个函数，这个函数要么是系统API，要么是我们自己实现的本地代码，一起编译，一起发布，也在同一个进程中一起执行。

#### 远程调用

被调用方法的具体实现不在同一个进程，而在别的进程，甚至别的电脑上。RPC一个重要思想就是使远程调用看起来象本地调用一样，调用者无需知道被调用接口具体在哪台机器上执行

![img](https://img-blog.csdnimg.cn/13f0797429ff49a99a0093d4a1b3def4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATm84Z-aUu-WfjueLrg==,size_20,color_FFFFFF,t_70,g_se,x_16)

#### [注册中心](https://blog.csdn.net/belongtocode/article/details/118639474)

**引言**

服务治理可以说是微服务系统中最为关键的一个设计要素，各个微服务都需要通过它来实现自动化的注册和发现。那么今天，我们就来聊聊实现服务治理的基本方法。

我们先来模拟一个业务场景，你感受一下。

假如我们要设计和开发一个分布式服务系统，对于一个完整的业务系统而言，服务在数量上通常都是具有一定规模的，而服务之间需要相互调用并形成复杂的访问链路。

那么这个时候，我们通常会面临以下两个挑战：

如何管理服务实例的数量？
如何管理服务实例的状态？
显然，如果一个系统中存在几十个、甚至上百个服务时，我们可能都无法明确系统中到底有哪些服务正在运行。而且由于自动扩容、服务重启等因素，服务实例的运行时状态也会经常变化。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/70bc56450ac06c3e715aa2689b332d05.png)

所以，为了更好地描述服务的运行时状态，我们可以对每个服务实例信息进行抽象，并通过更加统一、形象的方式表达出来，如下所示：

![img](https://img-blog.csdnimg.cn/img_convert/1e2a6821bacf9fa192f906583a1fb264.png)

不过，既然服务数量的增加以及服务实例的变化都不可避免，那么有什么好办法能够有效地管理这些服务实例呢？

这实际上就是一个服务治理的问题。一般来说，为了实现高效的服务治理，需要引入注册中心来管理服务的实例。
**什么是注册中心**

`注册中心是服务实例信息的存储仓库，也是服务提供者和服务消费者进行交互的桥梁。它主要提供了服务注册和服务发现这两大核心功能。`

![img](https://img-blog.csdnimg.cn/img_convert/90f05404608967e82e18e3999a4a7e59.png)

我们看这张服务注册流程图就知道，对于注册中心而言，服务的提供者和消费者都相当于是它的客户端，所以都内嵌了专门与注册中心实现交互的客户端组件。

针对服务的提供者而言，每当服务启动，就会通过这个注册中心的客户端组件，自动将自己注册到注册中心，这就是服务注册过程，有时候也叫服务发布过程。

而对于服务消费者来说，执行的是订阅操作而不是注册操作，也就是说它会对那些自己感兴趣的服务进行订阅，通过订阅操作就能从注册中心中，自动获取那些已经注册的服务提供者信息，这就是服务发现过程。

从图中我们还能发现服务消费者与提供者之间的一个明显差异点，也就是消费者持有一个本地缓存，保存着那些已经获取到的服务提供者的实例信息。

这个本地缓存有两方面的作用。一方面，服务消费者可以先通过查询本地缓存，来快速获取目标服务的实例信息，从而提高服务发现的效率；另一方面，如果注册中心出现不可用或者网络访问出现异常，那么消费者就无法从注册中心中获取服务实例信息，这时候基于本地缓存，也同样可以实现对已注册服务的正常调用。
**注册信息变更通知机制**

讲到这里，我们实际上就已经了解了 。通过获取注册中心中的服务实例信息，我们就可以掌握系统中服务的数量以及当前的运行时状态了。

但仍然有一个问题摆在我们面前，就是一旦服务的运行时状态发生了变更，我们又该如何有效获取这些变更信息呢？

这就需要在注册中心里进一步引入变更通知机制：

![img](https://img-blog.csdnimg.cn/img_convert/8d3db4e38de0b6d9e465a084ca18d664.png)

变更通知机制是实现注册中心的一大难点，因为这个过程涉及服务提供者、消费者和注册中心三者之间的数据同步问题，想要在分布式环境下实现数据同步是有挑战的。下面我就来给你介绍下两种主流的实现方法，一种是监听机制，一种是轮询机制。

1. 监听机制

   从架构设计来讲，状态变更管理可以采用注册中心本身具有的发布 - 订阅模式。

   因此也就诞生了服务监听机制。它可以用来确保服务消费者能够实时监控服务的更新状态，是一种被动接收变更通知的实现方案，一般是采用监听器和回调机制。

   ![img](https://img-blog.csdnimg.cn/img_convert/6c6516ac4e954ec898dd19cf1c4dec55.png)

   我们看服务监听机制图，服务消费者可以对这些具体的服务实例节点添加监听器，当这些节点发生变化时，例如服务 B 的第一个实例变得不可用、服务 C 的第一个实例地址发生变更，或者是服务 D 新增了一个实例 3，那么注册中心就能触发监听器中的回调函数，确保更新通知到每一个服务消费者。

   所以很显然，使用监听和通知机制具备实时的数据同步效果。

2. 轮询机制

   另一种确保状态信息同步的方式是采用轮询机制。这是一种主动拉取策略，即服务的消费者会定期调用注册中心提供的服务获取接口，以此获取最新的服务列表，并更新本地缓存。

   ![img](https://img-blog.csdnimg.cn/img_convert/5fea265e9b091f557b69bbc8d856ea1f.png)

   其实轮询机制在实现上就是一个定时器，我们需要重点考虑的问题就是轮询的频率。

   一方面，为了确保数据同步的时效性，轮询频率不能太短；但另一方面，考虑到轮询对注册中心的性能影响，也不能过于频繁地进行定时操作。一般来说，轮询频率控制在几十秒到几分钟之间是一种比较好的选择。

**Zookeeper**

Zookeeper 是`服务监听机制`实现策略的典型代表性工具，它本质上是一个树形结构，可以在树上创建临时节点，并对节点添加监听器。

监听器和服务集群建立长连接，并会实时关注节点的状态，同时，客户端存在一个回调函数，当节点状态发生变化时，就会通过监听器将这种变化传递到客户端并触发回调函数。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/162eb8ae95aafa2ad46e84192c5e2f8b.png)

#### JDK动态代理

在业务中使用动态代理，一般是为了给需要实现的方法添加预处理或者添加后续操作，但是不干预实现类的正常业务，把一些基本业务和主要的业务逻辑分离（日志操作）

基于JDK的动态代理就需要知道两个类：1.InvocationHandler（接口）、2.Proxy（类）

还要知道JDK是基于接口的动态代理

```java
//1.创建接口
public interface Subject {
    void hello(String param);
}
//2.实现接口
public class SubjectImpl implements Subject{
    @Override
    public void hello(String param) {
        System.out.println(param);
    }
}
//3.创建实现类的代理类
public class SubjectProxy implements InvocationHandler {
    private Subject subject;

    public SubjectProxy(Subject subject) {
        this.subject = subject;
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("-------------------begin----------------------");
        Object invoke = method.invoke(subject, args);
        System.out.println(invoke);
        System.out.println("-------------------end------------------------");
        return invoke;
    }
}
//4.代理类的实际调用
public class Main {
    public static void main(String[] args) {
        SubjectImpl subject = new SubjectImpl();
        SubjectProxy subjectProxy = new SubjectProxy(subject);
        Subject proxyInstance = (Subject) Proxy.newProxyInstance(subjectProxy.getClass().getClassLoader(), subject.getClass().getInterfaces(), subjectProxy);
        proxyInstance.hello("testProxy");
    }
}
```

输出：

```
-------------------begin----------------------
testProxy
null
-------------------end------------------------
```

#### Socket通信

> Socket 的中文翻译过来就是“套接字”。套接字是什么，我们先来看看它的英文含义：插座。
>
> socket起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“打开open –> 读写write/read –> 关闭close”模式来操作。我的理解就是Socket就是该模式的一个实现，socket即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭），这些函数我们在后面进行介绍。

**socket通信主要基于两种协议实现的**

(1)TCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，是一个工业标准的协议集，它是为广域网（WANs）设计的。

(2)UDP（User Data Protocol，用户数据报协议）是与TCP相对应的协议。它是属于TCP/IP协议族中的一种。

通过下图说明实现通信过程之间关系：
![img](https://img-blog.csdnimg.cn/05a51a3264794fbdbe7a421c1544af09.png)

###### socket通信过程

**通信过程介绍**

Socket 保证了不同计算机之间的通信，也就是网络通信。对于网站，通信模型是服务器与客户端之间的通信。两端都建立了一个 Socket 对象，然后通过 Socket 对象对数据进行传输。通常服务器处于一个无限循环，等待客户端的连接：

![img](https://img-blog.csdnimg.cn/0aea51d5f1484bba9428a3328baca8c3.png) 

根据[socket通信](https://so.csdn.net/so/search?q=socket通信&spm=1001.2101.3001.7020)基本流程图，总结通信的基本步骤：
服务器端：
第一步：创建一个用于监听连接的Socket对像；
第二步：用指定的端口号和服务器的ip建立一个EndPoint对像；
第三步：用socket对像的Bind()方法绑定EndPoint；
第四步：用socket对像的Listen()方法开始监听；
第五步：接收到客户端的连接，用socket对像的Accept()方法创建一个新的用于和客户端进行通信的socket对像;
第六步：通信结束后一定记得关闭socket;
客户端：
第一步：建立一个Socket对像；
第二步：用指定的端口号和服务器的ip建立一个EndPoint对像；
第三步：用socket对像的Connect()方法以上面建立的EndPoint对像做为参数，向服务器发出连接请求；
第四步：如果连接成功，就用socket对像的Send()方法向服务器发送信息；
第五步：用socket对像的Receive()方法接受服务器发来的信息 ;
第六步：通信结束后一定记得关闭socket； 

#### NIO通信

| IO     | NIO        |
| ------ | ---------- |
| 面向流 | 面向缓冲区 |
| 阻塞   | 非阻塞     |

**面向流与面向缓冲**

面向流意味着每次从流中读一个或多个字节，直至读取所有字节，他们没有被缓存在任何地方。此外它不能前后移动流中的数据。如果需要前后移动从流中读取的数据需要先将它缓存到一个缓冲区。NIO的缓冲导向方法略有不同，数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否缓冲区中包含所有你需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。

**阻塞与非阻塞IO**

阻塞意味着当一个线程在读写时，该线程被阻塞，直到有一些数据读取或写入结束，该线程在此期间不能干任何事情。

NIO非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。

**选择器**

Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。

**`注意：`**
**NIO的出现并不是要替代传统IO,而是在弥补传统IO的部分缺点，使用的场景不同。NIO虽然是非阻塞的，但是你在使用非阻塞write(ByteBuffer bf)时，当数据量较大时,可能会出现没有传输完整的现象，如果要保证数据传输完整,就要通过代码`while(bf.hasReaming())`和`while(已传输len<文件size)`去持续写入。这样的话会出现代码干预使其变成阻塞的了。而经过jdk不断的优化,inputSream和OutputStream几乎是传输速度最快的了,可以接近磁盘的写/读峰值（除了map内存映射），但是在有新的连接请求时却需要新的线程来控制，而线程的创建开销过于庞大，在线程间切换也有较大的消耗。总的来说，NIO适用于多条连接、多次请求，即需要多个线程多次操作，使用NIO可以减少创建线程和线程频繁切换的消耗；传统IO适用于少量用户，每次请求需要传输大量数据，但是请求次数少，使用传统IO可以提高传输的效率。**（这里所说的NIO代指非阻塞IO，传统IO代表阻塞IO）

![img](https://img-blog.csdnimg.cn/20190823161531365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc2MjEzMw==,size_16,color_FFFFFF,t_70)

#### 强类型与弱类型

**强类型：**

要求变量或者常量必须声明类型，并且只有在声明后才能使用。一经声明该变量就只能存储这种类型的值

赋值和运算过程中，参与该过程的数据类型必须一致

强制转换改变的是`变量的值`的类型，而没有改变变量的类型

**弱类型：**

一个变量可以赋不同数据类型的值

#### 服务注册与发现

**服务注册：**

就是将提供某个服务的模块信息（通常是服务的ip和端口）注册到一个公共的组件上（zookeeper/consul）

**服务发现：**

就是新注册的这份服务模块能够及时的被其他调用者发现。不管是服务新增和服务删减都能实现自动发现

可以理解为：

```
//服务注册
NameServer->register(newServer); 

//服务发现
NameServer->getAllServer(); 
```

**微服务时代的服务管理**

在微服务时代，我们所有的服务都被尽量拆分成最小的粒度，原先所有的服务都在混在1个server里，现在就被按照功能或者对象拆分成N个服务模块，这样做的好处是深度解耦，1个模块只负责自己的事情就好，能够实现快速的迭代更新。坏处就是服务的管理和控制变得异常的复杂和繁琐，人工维护难度变大。还有排查问题和性能变差（服务调用时的网络开销）

比如还是上面的模型架构，在微服务时代就会变成这样子：

![img](https://pic3.zhimg.com/80/v2-a99ddce97f9066f7d3ebb62ec397cf8a_1440w.webp)

**各个微服务相互独立，每个微服务，由多台机器或者单机器不同的实例组成，各个微服务之间错综复杂的相互关联调用**。

比如上面的图中，我们将原先1个server的服务进行了拆分，拆出了`User服务`，`Order服务`，`Goods服务`，`Search服务`等等。每个服务里有N台机器或者实例。每个服务还相互关联和调动。这种错综复杂的网络架构，使得这种服务的维护成本变得比之前困难了很多。

> 该服务管理下出现的问题：
>
> **在不用服务注册之前，我们可以想象一下，怎么去维护这种复制的关系网络呢**？答案就是：**写死！**。将其他模块的ip和端口写死在自己的配置文件里，甚至写死在代码里，每次要去新增或者移除1个服务的实例的时候，就得去通知其他所有相关联的服务去修改。随之而来的就是各个项目的配置文件的反复更新、每隔一段时间大规模的ip修改和机器裁撤，非常的痛苦。

###### 服务注册

还是上面服务模块的例子，我们看下用了服务注册和服务发现之后，我们的网络请求模块，发生了怎么的变化呢？先来看下，服务注册是怎么操作的。看下面的图：

![img](https://pic2.zhimg.com/80/v2-e0d57ebf56f9743a03f35e297934d9dd_1440w.webp)

每一个服务对应的机器或者实例在启动运行的时候，都去向名字服务集群注册自己，比如图中，`User服务`有6个docker实例，那么每个docker实例，启动后，都去把自己的信息注册到名字服务模块上去，同理`Order服务`也是一样。

对应的伪代码可以表示如下：

``` 
//给User服务申请1个独有的专属名字
UserNameServer = NameServer->apply('User');

//User服务下的6台docker实例启动后，都去注册自己
UserServer1 = {ip: 192.178.1.1, port: 3445}
UserNameServer->register(UserServer1);

......

UserServer6 = {ip: 192.178.1.6, port: 3445}
UserNameServer->register(UserServer6);

//给Order服务申请1个独有的专属名字
OrderNameServer = NameServer->apply('Order');

//开始注册
OrderServer1 = {ip: 192.178.1.1, port: 3446}
OrderNameServer->register(OrderServer1);

//给Search服务申请1个独有的专属名字
SearchNameServer = NameServer->apply('Search');

//开始注册
SearchServer1 = {ip: 192.178.1.1, port: 3447}
SearchNameServer->register(SearchServer1);
```

这样，每个服务的机器实例在启动后，就完成了注册的操作。注册的方式有很多的形式，不同的名字服务软件方式不一样，有HTTP接口形式，有RPC的方式，也有使用JSON格式的配置表的形式的。方式虽然不同，但是结果都是一样。

实例注册到名字服务上之后，接下来就是服务发现了。

###### 服务发现

我们把每个服务的机器实例注册到了名字服务器上之后，接下来，我们如何去发现我们需要调用的服务的信息呢？这就是服务发现了。

我们看下，服务发现是怎么做的：

![img](https://pic4.zhimg.com/80/v2-7e32eeb70fad22a91e7f8d97088d606b_1440w.webp)

在上图中，`Order`服务想要获取`User`服务相关的信息，首先向注册集群中心发送请求获取，然后就能收到`User`服务相关的信息。

伪代码可以表示如下：

```text
//服务发现，获取User服务的列表
list = NameServer->getAllServer('User'); 

//list的内容
[
    {
        "ip": "192.178.1.1",
        "port": 3445
    },
    {
        "ip": "192.178.1.2",
        "port": 3445
    },
    ......
    {
        "ip": "192.178.1.6",
        "port": 3445
    }
]

//服务发现，获取Goods服务的列表
list = NameServer->getAllServer('Goods');

//list的内容
[
    {
        "ip": "192.178.1.1",
        "port": 3788
    },
    {
        "ip": "192.178.1.2",
        "port": 3788
    },
    ......
    {
        "ip": "192.178.1.4",
        "port": 3788
    }
]
```

我们通过服务发现，就获得了`User`模块的所有的ip列表，然后，我们再用一定的负载均衡算法，或者干脆随机取1个ip，进行调用。

当然，也有些注册服务软件也提供了DNS解析功能或者负载均衡功能，它会直接返回给你一个可用的ip，你直接调用就可以了，不用自己去做选择。

这样，我们获取了服务的IP信息后，就可以进行调用了，如图所示：

![img](https://pic2.zhimg.com/80/v2-32a0d8785d533d4995c94b1baf6907b9_1440w.webp)

和服务注册的方式一样，服务发现的方式，不同的名字服务软件的方式也会不一样，有的是得自己发送HTTP接口去**轮训调用**，如果发现有更新，就更新自己本地的配置文件。有的是可以通过实时的**sub/pub**的方式实现的**自动发现服务**，当我订阅的这个服务内容发生了更新，就实时更新自己的配置文件。也有的是通过RPC的方式。方式虽然不同，但是结果都是一样。

**这样一来，我们就可以通过服务注册和发现的方式，维护各个服务IP列表的更新，各个模块只需要向名字服务中心去获取某个服务的IP就可以了，不用再写死IP。整个服务的维护也变得轻松了很多。彻底解放了双手！**

###### 健康检查

可能你会说，这样加了1个中间代理，饶了一个大圈子，感觉也挺费劲的，难道仅仅是为了解决新增服务，动态获取IP的问题吗？

当然不是！服务注册和服务发现，不仅仅解决了服务调用这种写死IP以及杂乱无章的管理的状态，更重要的一点是它还管理了服务器的存活状态，也就是**健康检查**。

很多名字服务软件都会提供健康检查功能。注册服务的这一组机器，当这个服务组的某台机器，如果出现宕机或者服务死掉的时候，就会标记这个实例的状态为故障，或者干脆剔除掉这台机器。这样一来，就实现了自动监控和管理。

健康检查有多重实现方式，比如有几秒就发一次健康检查心跳，如果返回的HTTP状态不是200，那么就判断这台服务不可用，对它进行标记。也可以执行一个shell脚本，看执行的返回结果，来标记状态等等。

![img](https://pic4.zhimg.com/80/v2-1f0bfa0d220315ef13b3e731932177e3_1440w.webp)

上图中，用心跳发送的方式来检查健康状态，当有1台机器出现异常，这样我们获取服务的时候，就能知道服务的健康状态了。

比如伪代码如下：

```text
//服务发现，获取User服务的列表
list = NameServer->getAllServer('User'); 

//list的内容
[
    {
        "ip": "192.178.1.1",
        "port": 3445,
        "status": "success"
    },
    {
        "ip": "192.178.1.2",
        "port": 3445,
        "status": "success"
    },
    ......
    {
        "ip": "192.178.1.6",
        "port": 3445
        "status": "error" //故障,出现错误
    }
]
```

我们通过判断列表里的`status`的状态是不是`success`来确认调用的服务是可用的。有些名字服务会提供DNS解析功能，直接就会把有问题的机器给去掉，你服务发现后的机器服务就是正常可用的。

同时，当服务不可用的时候，有些名字服务软件也会提供发送邮件或者消息功能，及时的提示你服务出现故障。这样一来，我们就通过健康检查功能，来帮我们及时的去规避问题，降低影响。

当出现故障的服务被修复后，服务重新启动后，健康检查会检查通过，然后这台机器就会被标记为健康，这样，服务发现，就又可以发现这台机器了。

这样，整个服务注册和服务发现，就实现了闭环。

![img](https://pic4.zhimg.com/80/v2-bc1cfc54f4cffb49e5d4645ca5cb3d8f_1440w.webp)

#### 工厂模式（未学完）

![img](https://img-blog.csdnimg.cn/img_convert/580938d63e68883fe0ee69164a623401.png)

这三种工程模式在设计模式的分类中都属于创建型模式，三种模式从上到下逐步抽象

##### 创建型模式：

创建型模式(Creational Pattern)对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。为了使软件的结构更加清晰，外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节，使整个系统的设计更加符合单一职责原则。

创建型模式隐藏了类的实例的创建细节，通过隐藏对象如何被创建和组合在一起达到使整个系统独立的目的。

工厂模式是创建型模式中比较重要的。工厂模式的主要功能就是帮助我们实例化对象。之所以名字中包含工厂模式四个字，是因为对象的实例化过程是通过工厂实现的，是用工厂代替 new 操作的。

**优点：**

- **可以使代码结构清晰，有效地封装变化**。在编程中，产品类的实例化有时候是比较复杂和多变的，通过工厂模式，将产品的实例化封装起来，使得调用者根本无需关心产品的实例化过程，只需依赖工厂即可得到自己想要的产品。
- **对调用者屏蔽具体的产品类**。如果使用工厂模式，调用者只关心产品的接口就可以了，至于具体的实现，调用者根本无需关心。即使变更了具体的实现，对调用者来说没有任何影响。
- **降低耦合度**。产品类的实例化通常来说是很复杂的，它需要依赖很多的类，而这些类对于调用者来说根本无需知道，如果使用了工厂方法，我们需要做的仅仅是实例化好产品类，然后交给调用者使用。对调用者来说，产品所依赖的类都是透明的。

**适用场景**

不管是简单工厂模式，工厂方法模式还是抽象工厂模式，他们具有类似的特性，所以他们的适用场景也是类似的。

首先，作为一种创建类模式，在任何需要生成**复杂对象**的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。

其次，工厂模式是一种典型的**解耦模式**，迪米特法则在工厂模式中表现的尤为明显。假如调用者自己组装产品需要增加依赖关系时，可以考虑使用工厂模式。将会大大降低对象之间的耦合度。

再次，由于工厂模式是依靠抽象架构的，它把实例化产品的任务交由实现类完成，**扩展性比较好**。也就是说，当需要系统有比较好的扩展性时，可以考虑工厂模式，不同的产品用不同的实现工厂来组装。

